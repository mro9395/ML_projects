{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting Anti Mask Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54kW7vI18TDj"
      },
      "source": [
        "# Detecting whether a Tweet is Anti Mask or Pro Mask\n",
        "<!-- Github link: https://github.com/mro9395/ML_projects/tree/main/03Twitter_Real_or_Missinformation -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTwNm4_cJk9h"
      },
      "source": [
        "## Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoubmxkwJfKK"
      },
      "source": [
        "# Import packages\n",
        "\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Bidirectional\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from keras.metrics import CategoricalAccuracy\n",
        "from keras.metrics import SparseCategoricalAccuracy\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from math import sqrt"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wH8Af4Le6qs"
      },
      "source": [
        "## Loading required data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzUAXbp6kV5A"
      },
      "source": [
        "# Load dataset of Tweets\n",
        "tweets = pd.read_csv('TweetBase.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu3411dok1TH"
      },
      "source": [
        "# Keep only tweets and labels\n",
        "data = tweets[['text','Human label']]\n",
        "\n",
        "# Drop null values\n",
        "data = data.dropna()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "uFluOdval8kG",
        "outputId": "b6694c61-814e-4eed-dbb6-e30ea2d36c78"
      },
      "source": [
        "# Get overall description of dataset\n",
        "data.describe()[:2]"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3343</td>\n",
              "      <td>3115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3102</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tweet label\n",
              "count   3343  3115\n",
              "unique  3102     2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Psnwi_JXw05-",
        "outputId": "76afb897-77aa-44cb-9206-7b7a1ab44cac"
      },
      "source": [
        "# Group by\n",
        "data.groupby('label').count()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>antimask</th>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>promask</th>\n",
              "      <td>2787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          tweet\n",
              "label          \n",
              "antimask    328\n",
              "promask    2787"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyBgoKGym_0V"
      },
      "source": [
        "# Rename columns\n",
        "data.columns = ['tweet','label']"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68LhD_v8qUXI"
      },
      "source": [
        "# Rename values and only keep antimask and promask tweets, drop neutral\n",
        "data['label'] = data['label'].map({1:'promask',-1:'antimask'})\n",
        "data = data.drop(data[data['label']==0].index)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDHBqR7JlCWc"
      },
      "source": [
        "# Split data in training and test\n",
        "trainingdata = data.sample(frac = 0.2)\n",
        "testdata = data.drop(trainingdata.index)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w42P8R6UYNqh",
        "outputId": "8889eca6-d540-4249-8c52-ee79406aaffb"
      },
      "source": [
        "# Print shapes of data\n",
        "print(trainingdata.shape)\n",
        "print(testdata.shape)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(669, 2)\n",
            "(2674, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEJ8XGp4WAhr"
      },
      "source": [
        "# # Show samples of tweets\n",
        "\n",
        "# print('1. Tweets that demonstrate misinformation:\\n')\n",
        "# for i in trainingdata[trainingdata['label']=='promask'].tweet[:7]:\n",
        "#     print('~', i)\n",
        "\n",
        "# print('\\n 2. Tweets that demonstrate real information:\\n')\n",
        "# for i in trainingdata[trainingdata['label']=='antimask'].tweet[:7]:\n",
        "#     print('~', i)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70dBdbhjXRIh"
      },
      "source": [
        "**Discussion of dataset**: With this dataset, I aim to build a model to predict whether a tweet has a Pro Mask or Anti Mask sentiment given the COVID-19 pandemic circumstances. Labels describe whether the tweets depict a Pro Mask or Anti Mask sentiment. These labeling has been made by humans so the range of error of mislabeling is very low. Out of the 3343 tweets of this dataset, 328 are Anti Mask tweets and 2787 are Pro Mask. The features are tokens of the content of tweets, while the target is a binary variable (Pro Mask vs Anti Mask).l or false fact-checked claims.\n",
        "\n",
        "I have personally collected the dataset that contains tweets between December 25, 2020 and January 22, 2021 using Twitter API. These dates were chosen since a COVID-19 cases surge occurred then. The geographical area contains only Florida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mbsEn4hy1d5"
      },
      "source": [
        "\n",
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwaeszUlJ9pV"
      },
      "source": [
        "### Prepare preprocessor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrbG7iM0xyg7"
      },
      "source": [
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(trainingdata.tweet)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen, max_words):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm3oEXabew5S"
      },
      "source": [
        "### Prepare Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyVH6TUfR2yK"
      },
      "source": [
        "# tokenize and pad X data\n",
        "X_train = preprocessor(trainingdata.tweet, maxlen=60, max_words=10000)\n",
        "X_test = preprocessor(testdata.tweet, maxlen=60, max_words=10000)\n",
        "\n",
        "# ohe encode Y data\n",
        "y_train = pd.get_dummies(trainingdata.label)\n",
        "y_test = pd.get_dummies(testdata.label)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgP4-b463nQ0",
        "outputId": "efa2a228-9e9e-4e1a-e586-78e9086f1c78"
      },
      "source": [
        "# Print shapes of data\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(669, 60)\n",
            "(2674, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiHkYyb0fgmO"
      },
      "source": [
        "## Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gep1hEGL1Jg4"
      },
      "source": [
        "# Declare maximum length of tweet\n",
        "\n",
        "maxlen = 60"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfTxRDk_R3ag"
      },
      "source": [
        "# Set function to evaluate models\n",
        "\n",
        "def model_eval_metrics(y_true, y_pred):\n",
        "    accuracy_eval = accuracy_score(y_true, y_pred)\n",
        "    f1_score_eval = f1_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
        "    precision_eval = precision_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
        "    recall_eval = recall_score(y_true, y_pred,average=\"macro\",zero_division=0)\n",
        "    mse_eval = 0\n",
        "    rmse_eval = 0\n",
        "    mae_eval = 0\n",
        "    r2_eval = 0\n",
        "    metricdata = {'accuracy': [accuracy_eval], 'f1_score': [f1_score_eval], 'precision': [precision_eval], 'recall': [recall_eval], 'mse': [mse_eval], 'rmse': [rmse_eval], 'mae': [mae_eval], 'r2': [r2_eval]}\n",
        "    finalmetricdata = pd.DataFrame.from_dict(metricdata)\n",
        "    return finalmetricdata"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3Jy_FcW6mMr"
      },
      "source": [
        "## Model 1: Embeddings with bidirectional LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb8njbp97Jlt"
      },
      "source": [
        "Here we use an embeddings layer of 64 features followed by a bidirectional LSTM of 32 features before flatten and a dense layer. This model has few layers than the others."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKop0bNIBUFP",
        "outputId": "35cc8b43-33d1-426d-e575-f10c2a96ab53"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 64, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(32)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
        "score = model.evaluate(X_test, y_test, batch_size=16)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 6s 66ms/step - loss: 0.5318 - acc: 0.7487 - val_loss: 0.3805 - val_acc: 0.8284\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 1s 41ms/step - loss: 0.3618 - acc: 0.8424 - val_loss: 0.3720 - val_acc: 0.8284\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 1s 41ms/step - loss: 0.3608 - acc: 0.8203 - val_loss: 0.3522 - val_acc: 0.8284\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 1s 40ms/step - loss: 0.3096 - acc: 0.8189 - val_loss: 0.3521 - val_acc: 0.8284\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 1s 43ms/step - loss: 0.2596 - acc: 0.8365 - val_loss: 0.3566 - val_acc: 0.8284\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 1s 41ms/step - loss: 0.2206 - acc: 0.8252 - val_loss: 0.3650 - val_acc: 0.8284\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 1s 40ms/step - loss: 0.1625 - acc: 0.8590 - val_loss: 0.3779 - val_acc: 0.8358\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 1s 42ms/step - loss: 0.1636 - acc: 0.9391 - val_loss: 0.3833 - val_acc: 0.8358\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 1s 41ms/step - loss: 0.1234 - acc: 0.9557 - val_loss: 0.5840 - val_acc: 0.8284\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 1s 40ms/step - loss: 0.4261 - acc: 0.8534 - val_loss: 0.3740 - val_acc: 0.8284\n",
            "168/168 [==============================] - 1s 8ms/step - loss: 0.4011 - acc: 0.8336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "GFs38g5lTuXG",
        "outputId": "233c54eb-2567-4b62-f200-70bf6f6a831e"
      },
      "source": [
        "# Calculate metrics of evaluation \n",
        "\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels\n",
        "\n",
        "model_eval_metrics( y_test_labels,predicted_labels)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.833583</td>\n",
              "      <td>0.537883</td>\n",
              "      <td>0.662618</td>\n",
              "      <td>0.540049</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.833583  0.537883   0.662618  0.540049    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RH5UipBm6n2-"
      },
      "source": [
        "## Model 2: Embeddings with bidirectional and stacked LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oSQUhP265c5"
      },
      "source": [
        "Here we use an embeddings layer with 32 features rather than 64, one bidirectional LSTM and three stacked LSTM layers before the dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cucGqnXBUpH",
        "outputId": "8c5334c8-a85c-40ee-c554-c263bf869b2c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32, input_length=maxlen))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(16))\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=16,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 13s 159ms/step - loss: 0.4820 - acc: 0.8025 - val_loss: 0.3805 - val_acc: 0.8284\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.3161 - acc: 0.8769 - val_loss: 0.3799 - val_acc: 0.8284\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.3913 - acc: 0.8210 - val_loss: 0.3715 - val_acc: 0.8284\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 3s 96ms/step - loss: 0.3686 - acc: 0.8169 - val_loss: 0.3590 - val_acc: 0.8284\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 3s 95ms/step - loss: 0.2775 - acc: 0.8152 - val_loss: 0.4336 - val_acc: 0.8209\n",
            "Epoch 6/10\n",
            "34/34 [==============================] - 3s 98ms/step - loss: 0.1715 - acc: 0.9190 - val_loss: 0.4682 - val_acc: 0.7388\n",
            "Epoch 7/10\n",
            "34/34 [==============================] - 3s 99ms/step - loss: 0.1322 - acc: 0.9592 - val_loss: 0.5150 - val_acc: 0.7687\n",
            "Epoch 8/10\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0953 - acc: 0.9649 - val_loss: 0.4643 - val_acc: 0.7985\n",
            "Epoch 9/10\n",
            "34/34 [==============================] - 3s 97ms/step - loss: 0.0925 - acc: 0.9472 - val_loss: 0.4155 - val_acc: 0.8433\n",
            "Epoch 10/10\n",
            "34/34 [==============================] - 3s 100ms/step - loss: 0.0773 - acc: 0.9314 - val_loss: 0.6737 - val_acc: 0.7090\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "8cJUP8eSVmga",
        "outputId": "bb178300-696f-4cbf-d70f-b0ec2250ff3e"
      },
      "source": [
        "# Calculate metrics of evaluation \n",
        "\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels\n",
        "\n",
        "model_eval_metrics( y_test_labels,predicted_labels)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.771503</td>\n",
              "      <td>0.599975</td>\n",
              "      <td>0.596817</td>\n",
              "      <td>0.603875</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.771503  0.599975   0.596817  0.603875    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK0lPWhmVKpf"
      },
      "source": [
        "## Model 3: Embeddings with stacked 1D Convolutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpNK_eYK6p_v"
      },
      "source": [
        "Here a model with an embeddings layer will be used along three stacked 1D Convolution layers using MaxPooling. Finally, a flatten process is used before the dense layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reNeIN6WVJ5m",
        "outputId": "8581ab88-988e-40fa-ebc8-f8da17987c1e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32, input_length=maxlen))\n",
        "model.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "model.add(layers.MaxPooling1D())\n",
        "model.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "model.add(layers.MaxPooling1D())\n",
        "model.add(layers.Conv1D(32, 7, activation='relu')) \n",
        "model.add(layers.MaxPooling1D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "17/17 [==============================] - 2s 63ms/step - loss: 0.6520 - acc: 0.7913 - val_loss: 0.4072 - val_acc: 0.8284\n",
            "Epoch 2/10\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.3977 - acc: 0.8333 - val_loss: 0.3729 - val_acc: 0.8284\n",
            "Epoch 3/10\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.3531 - acc: 0.8247 - val_loss: 0.3594 - val_acc: 0.8284\n",
            "Epoch 4/10\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.3570 - acc: 0.8108 - val_loss: 0.3603 - val_acc: 0.8284\n",
            "Epoch 5/10\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2742 - acc: 0.8438 - val_loss: 0.3599 - val_acc: 0.8284\n",
            "Epoch 6/10\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2782 - acc: 0.8148 - val_loss: 0.3750 - val_acc: 0.8284\n",
            "Epoch 7/10\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2501 - acc: 0.8157 - val_loss: 0.3946 - val_acc: 0.8284\n",
            "Epoch 8/10\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.2110 - acc: 0.8106 - val_loss: 0.4483 - val_acc: 0.8284\n",
            "Epoch 9/10\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2052 - acc: 0.8068 - val_loss: 0.4860 - val_acc: 0.8284\n",
            "Epoch 10/10\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1580 - acc: 0.8295 - val_loss: 0.5702 - val_acc: 0.8284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "g_ug4vyqbARE",
        "outputId": "543d7a7a-0840-428f-f50d-b5b4bc0c9cea"
      },
      "source": [
        "# Calculate metrics of evaluation \n",
        "\n",
        "y_pred = model.predict(X_test).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "\n",
        "y_test_labels=y_test.idxmax(axis=1) #extract labels from one hot encoded y_test object\n",
        "y_test_labels=list(y_test.idxmax(axis=1)) #returns a pandas series of predicted labels\n",
        "\n",
        "model_eval_metrics( y_test_labels,predicted_labels)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.835453</td>\n",
              "      <td>0.457419</td>\n",
              "      <td>0.917695</td>\n",
              "      <td>0.501134</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   accuracy  f1_score  precision    recall  mse  rmse  mae  r2\n",
              "0  0.835453  0.457419   0.917695  0.501134    0     0    0   0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GAxsK-vprnz"
      },
      "source": [
        "**Discussion**: The three models have different results, although the accuracy is similar between model 1 and 3. Given that this model deals with imbalanced classes (there are a lot more Pro Mask tweets than Anti Mask), accuracy might not be the best metric to compare. So, I will use F1 score. According to this, the Model 2 with a Bidirectional LSTM and three stacked LSTM has the best score. The more complex architecture of this model might explain why it balances well both recall and precision.\n",
        "\n",
        "Even though Model 1 has more potential meaningful features (64) the F1 is not as high as Model 2, which implies that keeping the value to 32 might be sufficient for this dataset. Anyhow, Model 1 has a higher precision. So, if our aim is to have very specific results, Model 1 might be a better alternative than 2. But the best performing model in terms of precision is Model 3, the use of three 1D Convolution layers provides a very high precision, but a bad recall. The use of MaxPooling instead of Average Pooling might be causing the model to be more sensible to distinguish the tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnZWbOS-ukJG"
      },
      "source": [
        "## Feeding synthetic tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "754HI9HWe3i1",
        "outputId": "32da84e2-4fb6-4f94-9d6d-a2b46133f6c5"
      },
      "source": [
        "# Use model 2\n",
        "y_pred = model.predict(preprocessor(pd.Series(['masks dont work',\n",
        "                                               'covid is a plan',\n",
        "                                               'end masks',\n",
        "                                               'masks save lives',\n",
        "                                               'vaccines are good',\n",
        "                                               'people must use masks']), maxlen=60, max_words=10000)).argmax(axis=1)\n",
        "predicted_labels = [y_test.columns[i] for i in y_pred]\n",
        "predicted_labels"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['antimask', 'antimask', 'antimask', 'promask', 'promask', 'antimask']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkCPoj_4xjAs"
      },
      "source": [
        "**Discussion**: Using Model 2 and these samples, we observe that it delivers a good result classifying Anti Mask and pro Mask sentiments. Only the last one has been misclassified. It seems that the use of strong modifiers like 'must' or 'dont' might make the tweet more probable of being classified as Anti Mask. Positive words like 'save', 'lives' or 'good' might be have the oppposite effect (like the vaccine example). It looks promising that the model could differentiate 'covid is a plan' as Anti Mask given that the sentence looks pretty neutral."
      ]
    }
  ]
}